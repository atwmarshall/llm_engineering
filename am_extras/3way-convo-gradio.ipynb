{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0a8ab2b-6134-4104-a1bc-c3cd7ea4cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for google\n",
    "# in rare cases, this seems to give an error on some systems, or even crashes the kernel\n",
    "# If this happens to you, simply ignore this cell - I give an alternative approach for using Gemini later\n",
    "import google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1179b4c5-cd1f-4131-a876-4c9f3f38d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AIzaSyC1\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "797fe7b0-ad43-42d2-acf0-e4f309b112f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "425ed580-808d-429b-85b0-6cba50ca1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the set up code for Gemini\n",
    "# Having problems with Google Gemini setup? Then just ignore this cell; when we use Gemini, I'll give you an alternative that bypasses this library altogether\n",
    "\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2271f8d-ea72-446c-8a6e-cd2dc38b620f",
   "metadata": {},
   "source": [
    "# Three way convo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45ae9e5d-b281-48dc-b0b3-d604956b0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_via_openai_client = OpenAI(\n",
    "    api_key=google_api_key, \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98354b88-14c2-4035-a208-257a8c0b2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5788adef-d66b-45db-97b8-47400457afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words = \"three\"\n",
    "system_prompt_base_improv_game = f\"ONLY RETURN {number_of_words} WORDS. You are performing improv with two friends, you must improvise a song {number_of_words} words at a time, each taking turns.  You must only contribute {number_of_words} words a turn!\"\n",
    "system_prompt_beginner = system_prompt_base_improv_game +  \" You are a beginner at improv and occasionally get a word with not quite the right meaning but generally you're rhythmic just not perfectly all the time!\"\n",
    "system_prompt_cheeky_expert = system_prompt_base_improv_game +  \" You are an expert at improv but a bit cheeky in that you always get the right rhythm, but you always cheekily change the song to go somewhere unexpected with \\\n",
    "your word choice!  The amount you change the song direction varies\"\n",
    "system_prompt_expert = system_prompt_base_improv_game +  \" You are an expert at improv and used to dealing with others getting the rhyme/meaning slightly wrong and you can either bring the conversation back or embrace a mistake. \\\n",
    "One thing is for sure, you're an entertainer!\"\n",
    "\n",
    "def reset_messages():\n",
    "    gpt_messages = [\"The wheels on\"]#[\"The wheels on\"]\n",
    "    claude_messages = [\"\"]#[\"the bus go\"]\n",
    "    gemini_messages = [\"\"]#[\"round and round\"]\n",
    "    return gpt_messages, claude_messages, gemini_messages\n",
    "\n",
    "\n",
    "gpt_messages, claude_messages, gemini_messages = reset_messages()\n",
    "\n",
    "def call_ai(messages, model='llama3.2'):\n",
    "    result = openai.chat.completions.create(\n",
    "        model = MODEL,\n",
    "        messages = messages\n",
    "    )\n",
    "    output = result.choices[0].message.content\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "def call_assistant(system_prompt, assistant_no):\n",
    "    '''\n",
    "    system_prompt: str -> explain your assistants role in the conversation\n",
    "    assistant_no: int [0,2] -> \n",
    "    '''\n",
    "    messages = [\n",
    "        {'role': 'system', 'content':system_prompt}\n",
    "    ]\n",
    "    \n",
    "    a_role = 'assistant' if assistant_no == 0 else 'user'\n",
    "    b_role = 'assistant' if assistant_no == 1 else 'user'\n",
    "    c_role = 'assistant' if assistant_no == 2 else 'user'\n",
    "    \n",
    "    for a, b, c in zip(a_messages, b_messages, c_messages):\n",
    "        if a != \"\": messages.append({'role': a_role, 'content':a})\n",
    "        if b != \"\": messages.append({'role': b_role, 'content':b}) \n",
    "        if c != \"\": messages.append({'role': c_role, 'content':c})\n",
    "    \n",
    "    if assistant_no == 0:\n",
    "        pass\n",
    "    elif assistant_no == 1:\n",
    "        messages.append({'role': 'user', 'content':a_messages[-1]})\n",
    "    elif assistant_no == 2:\n",
    "        messages.append({'role': 'user', 'content':a_messages[-1]})\n",
    "        messages.append({'role': 'user', 'content':b_messages[-1]})\n",
    "    \n",
    "    return call_ai(messages)\n",
    "\n",
    "\n",
    "def call_beginner():\n",
    "    messages = [\n",
    "        {'role': 'system', 'content':system_prompt_beginner}\n",
    "    ]\n",
    "    for gpt, claude, gemini in zip(gpt_messages, claude_messages, gemini_messages):\n",
    "        if gpt != \"\": messages.append({'role': 'assistant', 'content':gpt})\n",
    "        if claude != \"\": messages.append({'role': 'user', 'content':claude}) \n",
    "        if gemini != \"\": messages.append({'role': 'user', 'content':gemini})\n",
    "    \n",
    "    return call_ai(messages)\n",
    "\n",
    "\n",
    "def call_cheeky():\n",
    "    messages = [\n",
    "        {'role': 'system', 'content':system_prompt_cheeky_expert}\n",
    "    ]\n",
    "    for gpt, cla, gem in zip(gpt_messages, claude_messages, gemini_messages):\n",
    "        if gpt != \"\": messages.append({'role': 'user', 'content':gpt})\n",
    "        if cla != \"\": messages.append({'role': 'assistant', 'content':cla})\n",
    "        if gem != \"\": messages.append({'role': 'user', 'content':gem})\n",
    "    messages.append({'role': 'user', 'content':gpt_messages[-1]})\n",
    "    \n",
    "    return call_ai(messages)\n",
    "\n",
    "\n",
    "def call_expert():\n",
    "    messages = [\n",
    "        {'role': 'system', 'content':system_prompt_expert}\n",
    "    ]\n",
    "    for gpt, claude, gemini in zip(gpt_messages, claude_messages, gemini_messages):\n",
    "        if gpt != \"\": messages.append({'role': 'user', 'content':gpt})\n",
    "        if claude != \"\": messages.append({'role': 'user', 'content':claude})\n",
    "        if gemini != \"\": messages.append({'role': 'assistant', 'content':gemini})\n",
    "    messages.append({'role': 'user', 'content':gpt_messages[-1]})\n",
    "    messages.append({'role': 'user', 'content':claude_messages[-1]})\n",
    "    \n",
    "    return call_ai(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4577b44-6b17-4e86-8d90-1f577aa52f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The wheels on'] [''] ['']\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    gpt_messages,\n",
    "    claude_messages,\n",
    "    gemini_messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5356352a-98a1-4709-a63c-824c475e518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_messages.append(call_beginner())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c94454bb-ba80-4899-be76-bc63f20912cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the bus go round\n"
     ]
    }
   ],
   "source": [
    "claude_messages.append(call_cheeky())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a16e5e46-6fa5-4bd1-a2de-58b26d2271d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round and round\n"
     ]
    }
   ],
   "source": [
    "gemini_messages.append(call_expert())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37bc55a2-a10b-49a7-b208-515fd055f159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Beginner: and never stop\n",
      "2Cheeky expert: till they hit\n",
      "3Expert: the ground with\n",
      "1Beginner: a loud CRASH\n",
      "2Cheeky expert: that echoes loudly\n",
      "3Expert: and startling everyone\n",
      "1Beginner: on the sidewalk\n",
      "2Cheeky expert: including a kitten\n",
      "3Expert: who's quite startled\n"
     ]
    }
   ],
   "source": [
    "def my_improv_song():\n",
    "    reset_messages()\n",
    "    for i in range(3):\n",
    "        print(\"1Beginner: \", end=\"\")\n",
    "        gpt_messages.append(call_beginner())\n",
    "        print(\"2Cheeky expert: \", end=\"\")\n",
    "        claude_messages.append(call_cheeky())\n",
    "        print(\"3Expert: \", end=\"\")\n",
    "        gemini_messages.append(call_expert())\n",
    "\n",
    "my_improv_song()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ef12e-c3c3-47ae-8895-3881abd17bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abfb6a34-7e20-48cd-9f85-a78ffdd9b892",
   "metadata": {},
   "source": [
    "# Adding Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c71fef0-c4a0-410d-ae7c-d75aca6c2974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def my_func(inp1, inp2):\n",
    "    return inp1 + inp2\n",
    "\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=my_func,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Beginner ai improv singer: Start an improv song with this line:\"),\n",
    "        gr.Textbox(label=\"Cheeky expert ai improv singer: and this optional 2nd line\"),\n",
    "        gr.Textbox(label=\"Expert ai improv singer: and this optional 3rd line\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Markdown(label=\"Song (it may not be musical):\")\n",
    "    ],\n",
    "    allow_flagging='never'\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6e4d39-07dd-4707-8617-d3991afda1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
